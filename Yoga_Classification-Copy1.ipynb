{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IngaSamoneneko/Yoga_Classification/blob/master/Yoga_Classification-Copy1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nErIhHVhKIUA",
        "outputId": "45cd7082-37f7-4b59-f39f-4eb7094c21d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nErIhHVhKIUA",
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "id": "b7fd5150-8197-48ea-af7c-cf2a66a802ce",
      "metadata": {
        "id": "b7fd5150-8197-48ea-af7c-cf2a66a802ce"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from math import ceil\n",
        "from sklearn.metrics import f1_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "id": "1664d45d-61a3-4c57-bfca-17be91f08710",
      "metadata": {
        "id": "1664d45d-61a3-4c57-bfca-17be91f08710",
        "outputId": "46f72014-0cfd-4baa-f6c1-c69937c0e3ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Використовується пристрій: cuda\n"
          ]
        }
      ],
      "source": [
        "# ==========================\n",
        "# CONFIG\n",
        "# ==========================\n",
        "ROOT_PATH  = '/content/drive/MyDrive/ML_Bootcamp_Data'\n",
        "IMAGE_PATH = os.path.join(ROOT_PATH, 'images')\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 6\n",
        "EPOCHS = 15  # Set higher after testing\n",
        "IMG_SIZE = 128  # Smaller for faster training\n",
        "\n",
        "print(\"Використовується пристрій:\", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "id": "5fe4e7a4-a077-4af4-9bed-2acdd2da578d",
      "metadata": {
        "id": "5fe4e7a4-a077-4af4-9bed-2acdd2da578d"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# ЗАВАНТАЖЕННЯ ДАНИХ\n",
        "# ==========================\n",
        "train_df = pd.read_csv(os.path.join(ROOT_PATH, \"train.csv\"))\n",
        "train_df, val_df = train_test_split(\n",
        "    train_df, test_size=0.2,\n",
        "    stratify=train_df[\"class_6\"], random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "id": "b329800e-3e08-4645-9173-ad4974377baf",
      "metadata": {
        "id": "b329800e-3e08-4645-9173-ad4974377baf"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# ТРАНСФОРМИ\n",
        "# ==========================\n",
        "train_transform = transforms.Compose([\n",
        "    #transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomResizedCrop((IMG_SIZE, IMG_SIZE), scale=(0.6, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "id": "509cd612-06de-4467-a8ca-288e80eba852",
      "metadata": {
        "id": "509cd612-06de-4467-a8ca-288e80eba852"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# КЛАС Dataset\n",
        "# ==========================\n",
        "class YogaDataset(Dataset):\n",
        "    def __init__(self, df, root_dir, transform=None, folder=\"train_images\", has_labels=True):\n",
        "        self.df = df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.folder = folder\n",
        "        self.has_labels = has_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.df.iloc[idx][\"image_id\"]\n",
        "        img_path = os.path.join(self.root_dir, self.folder, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.has_labels:\n",
        "            label = self.df.iloc[idx][\"class_6\"]\n",
        "            return image, label\n",
        "        else:\n",
        "            return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "id": "cc2be2a3-3b00-4458-8bd6-892278cf859d",
      "metadata": {
        "id": "cc2be2a3-3b00-4458-8bd6-892278cf859d"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# DATA LOADERS\n",
        "# ==========================\n",
        "train_dataset = YogaDataset(df=train_df, root_dir=IMAGE_PATH, transform=train_transform, folder=\"train_images\", has_labels=True)\n",
        "val_dataset = YogaDataset(df=val_df, root_dir=IMAGE_PATH, transform=val_transform, folder=\"train_images\", has_labels=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1,pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1,pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "id": "0314eb63-4c72-43df-b14f-fc443e7a0019",
      "metadata": {
        "id": "0314eb63-4c72-43df-b14f-fc443e7a0019"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# ПРОСТА СNN-МОДЕЛЬ\n",
        "# ==========================\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64, NUM_CLASSES)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = SimpleCNN().to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Пристрій: {DEVICE} | Train samples: {len(train_dataset)} | Val samples: {len(val_dataset)}\")\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_one_epoch(model, train_loader, criterion, optimizer, epoch)\n",
        "    val_acc = evaluate(model, val_loader)\n",
        "    print(f\"[Епоха {epoch}] Val Acc: {val_acc:.2f}%\")\n",
        "    scheduler.step(val_acc)"
      ],
      "metadata": {
        "id": "Lb_CbgS-K23A",
        "outputId": "95494c4d-3bf6-4ab1-feda-6577c38c1cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        }
      },
      "id": "Lb_CbgS-K23A",
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пристрій: cuda | Train samples: 1888 | Val samples: 472\n",
            "[Епоха 1] Train Loss: 1.7934 | Train Acc: 16.05%\n",
            "[Епоха 1] Val Acc: 17.58%\n",
            "[Епоха 2] Train Loss: 1.7931 | Train Acc: 16.15%\n",
            "[Епоха 2] Val Acc: 17.58%\n",
            "[Епоха 3] Train Loss: 1.7933 | Train Acc: 16.31%\n",
            "[Епоха 3] Val Acc: 17.58%\n",
            "[Епоха 4] Train Loss: 1.7930 | Train Acc: 16.58%\n",
            "[Епоха 4] Val Acc: 17.58%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-228-43d0b5fab797>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Пристрій: {DEVICE} | Train samples: {len(train_dataset)} | Val samples: {len(val_dataset)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Епоха {epoch}] Val Acc: {val_acc:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-224-c8b91bc15f80>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrunning_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# TRANSFER LEARNING: ResNet18 (оновлений синтаксис)\n",
        "# ==========================\n",
        "# Завантажуємо ResNet18 з рекомендованими ImageNet-вагами\n",
        "resnet = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "\n",
        "# Розморожуємо layer2, layer3 і layer4\n",
        "for name, param in resnet.named_parameters():\n",
        "    if name.startswith(\"layer2\") or name.startswith(\"layer3\") or name.startswith(\"layer4\"):\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Заміна останнього fc-шару: вхід = num_ftrs, вихід = 6 класів\n",
        "num_ftrs = resnet.fc.in_features\n",
        "resnet.fc = nn.Sequential(\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(num_ftrs, NUM_CLASSES)\n",
        ")\n",
        "\n",
        "model = resnet.to(DEVICE)\n"
      ],
      "metadata": {
        "id": "fhJINY7CnrRx"
      },
      "id": "fhJINY7CnrRx",
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "id": "71018858-e4c1-4b17-9f94-d60aff93f6bc",
      "metadata": {
        "id": "71018858-e4c1-4b17-9f94-d60aff93f6bc"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# CLASS WEIGHTS\n",
        "# ==========================\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_df['class_6']), y=train_df['class_6'])\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "id": "b61db891-0f9f-4e3e-ba23-cfce615b7ed1",
      "metadata": {
        "id": "b61db891-0f9f-4e3e-ba23-cfce615b7ed1"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# LOSS, OPTIMIZER\n",
        "# ==========================\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "params_to_update = [\n",
        "    {\"params\": resnet.layer2.parameters(), \"lr\": 1e-5},\n",
        "    {\"params\": resnet.layer3.parameters(), \"lr\": 1e-4},\n",
        "    {\"params\": resnet.layer4.parameters(), \"lr\": 1e-4},\n",
        "    {\"params\": resnet.fc.parameters(),    \"lr\": 1e-3},\n",
        "]\n",
        "\n",
        "optimizer = optim.Adam(params_to_update, weight_decay=1e-4)\n",
        "\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='max',         # спираємося на максимізацію Validation Accuracy\n",
        "    factor=0.5,         # зменшувати LR вполовину\n",
        "    patience=2\n",
        ")\n",
        "\n",
        "#scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "id": "2203afb7-dfe3-4594-a0b7-9e40e57a25db",
      "metadata": {
        "id": "2203afb7-dfe3-4594-a0b7-9e40e57a25db"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# ФУНКЦІЯ ВАЛІДАЦІЇ\n",
        "# ==========================\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return 100 * correct / total\n",
        "\n",
        "\n",
        "def evaluate_with_f1(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "    # Обчислюємо F1-метрику (зважене середнє по класах)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    # Додатково можна вивести classification report\n",
        "    report = classification_report(all_labels, all_preds, digits=4)\n",
        "    return f1, report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "id": "54769224-90d7-409e-b566-77c28d14522f",
      "metadata": {
        "id": "54769224-90d7-409e-b566-77c28d14522f"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# ФУНКЦІЯ ТРЕНУВАННЯ ЗА ЕПОХУ\n",
        "# ==========================\n",
        "def train_one_epoch(model, loader, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    avg_loss = running_loss / len(loader)\n",
        "    train_acc = 100 * correct / total\n",
        "    print(f\"[Епоха {epoch}] Train Loss: {avg_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "id": "56e5d063-378e-45e1-875d-dbc89322427f",
      "metadata": {
        "id": "56e5d063-378e-45e1-875d-dbc89322427f",
        "outputId": "970fdfd1-83be-4d7f-b806-f57365390a32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пристрій: cuda | Train samples: 1888 | Val samples: 472\n",
            "[Епоха 1] Train Loss: 1.7488 | Train Acc: 30.40%\n",
            "[Епоха 1] Val Acc: 48.94%\n",
            "[Епоха 2] Train Loss: 1.2070 | Train Acc: 53.71%\n",
            "[Епоха 2] Val Acc: 56.78%\n",
            "[Епоха 3] Train Loss: 0.9737 | Train Acc: 62.87%\n",
            "[Епоха 3] Val Acc: 57.84%\n",
            "[Епоха 4] Train Loss: 0.7852 | Train Acc: 69.33%\n",
            "[Епоха 4] Val Acc: 63.98%\n",
            "[Епоха 5] Train Loss: 0.6877 | Train Acc: 72.67%\n",
            "[Епоха 5] Val Acc: 65.04%\n",
            "[Епоха 6] Train Loss: 0.5291 | Train Acc: 79.18%\n",
            "[Епоха 6] Val Acc: 67.37%\n",
            "[Епоха 7] Train Loss: 0.4302 | Train Acc: 83.21%\n",
            "[Епоха 7] Val Acc: 68.43%\n",
            "[Епоха 8] Train Loss: 0.3692 | Train Acc: 86.28%\n",
            "[Епоха 8] Val Acc: 70.55%\n",
            "[Епоха 9] Train Loss: 0.3370 | Train Acc: 87.76%\n",
            "[Епоха 9] Val Acc: 68.22%\n",
            "[Епоха 10] Train Loss: 0.2771 | Train Acc: 89.14%\n",
            "[Епоха 10] Val Acc: 71.40%\n",
            "[Епоха 11] Train Loss: 0.2426 | Train Acc: 91.21%\n",
            "[Епоха 11] Val Acc: 72.25%\n",
            "[Епоха 12] Train Loss: 0.2158 | Train Acc: 92.32%\n",
            "[Епоха 12] Val Acc: 73.31%\n",
            "[Епоха 13] Train Loss: 0.1835 | Train Acc: 93.27%\n",
            "[Епоха 13] Val Acc: 71.82%\n",
            "[Епоха 14] Train Loss: 0.1426 | Train Acc: 94.65%\n",
            "[Епоха 14] Val Acc: 74.15%\n",
            "[Епоха 15] Train Loss: 0.1423 | Train Acc: 94.60%\n",
            "[Епоха 15] Val Acc: 71.82%\n"
          ]
        }
      ],
      "source": [
        "# ==========================\n",
        "# ТРЕНУВАННЯ ТА ВАЛІДАЦІЯ\n",
        "# ==========================\n",
        "print(f\"Пристрій: {DEVICE} | Train samples: {len(train_dataset)} | Val samples: {len(val_dataset)}\")\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_one_epoch(model, train_loader, criterion, optimizer, epoch)\n",
        "    val_acc = evaluate(model, val_loader)\n",
        "    print(f\"[Епоха {epoch}] Val Acc: {val_acc:.2f}%\")\n",
        "    scheduler.step(val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_f1 = 0.0\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_one_epoch(model, train_loader, criterion, optimizer, epoch)\n",
        "    val_acc = evaluate(model, val_loader)\n",
        "    val_f1, val_report = evaluate_with_f1(model, val_loader)\n",
        "    print(f\"[Епоха {epoch}] Val Acc: {val_acc:.2f}%  |  Val F1 (weighted): {val_f1:.4f}\")\n",
        "    print(\"Classification Report:\\n\", val_report)\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "\n",
        "print(f\"Найкращий Val F1 (weighted): {best_val_f1:.4f}\")"
      ],
      "metadata": {
        "id": "ABGv3SImHwc1",
        "outputId": "eb7f2558-a8e2-4a1f-e746-72d692adf378",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ABGv3SImHwc1",
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Епоха 1] Train Loss: 1.8077 | Train Acc: 28.92%\n",
            "[Епоха 1] Val Acc: 46.19%  |  Val F1 (weighted): 0.4479\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4643    0.7723    0.5799       101\n",
            "           1     0.4375    0.5000    0.4667        98\n",
            "           2     0.4286    0.4355    0.4320        62\n",
            "           3     0.4375    0.3684    0.4000        38\n",
            "           4     0.6667    0.2975    0.4114       121\n",
            "           5     0.3256    0.2692    0.2947        52\n",
            "\n",
            "    accuracy                         0.4619       472\n",
            "   macro avg     0.4600    0.4405    0.4308       472\n",
            "weighted avg     0.4885    0.4619    0.4479       472\n",
            "\n",
            "[Епоха 2] Train Loss: 1.2815 | Train Acc: 51.54%\n",
            "[Епоха 2] Val Acc: 49.79%  |  Val F1 (weighted): 0.4812\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5338    0.7030    0.6068       101\n",
            "           1     0.4677    0.5918    0.5225        98\n",
            "           2     0.4078    0.6774    0.5091        62\n",
            "           3     0.3830    0.4737    0.4235        38\n",
            "           4     0.7727    0.2810    0.4121       121\n",
            "           5     0.5714    0.2308    0.3288        52\n",
            "\n",
            "    accuracy                         0.4979       472\n",
            "   macro avg     0.5227    0.4929    0.4671       472\n",
            "weighted avg     0.5568    0.4979    0.4812       472\n",
            "\n",
            "[Епоха 3] Train Loss: 0.9799 | Train Acc: 61.39%\n",
            "[Епоха 3] Val Acc: 57.42%  |  Val F1 (weighted): 0.5705\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6000    0.6832    0.6389       101\n",
            "           1     0.5447    0.6837    0.6063        98\n",
            "           2     0.5714    0.6452    0.6061        62\n",
            "           3     0.4186    0.4737    0.4444        38\n",
            "           4     0.7463    0.4132    0.5319       121\n",
            "           5     0.5000    0.5192    0.5094        52\n",
            "\n",
            "    accuracy                         0.5742       472\n",
            "   macro avg     0.5635    0.5697    0.5562       472\n",
            "weighted avg     0.5966    0.5742    0.5705       472\n",
            "\n",
            "[Епоха 4] Train Loss: 0.8206 | Train Acc: 67.58%\n",
            "[Епоха 4] Val Acc: 61.65%  |  Val F1 (weighted): 0.6191\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7143    0.5941    0.6486       101\n",
            "           1     0.6019    0.6633    0.6311        98\n",
            "           2     0.6508    0.6613    0.6560        62\n",
            "           3     0.4242    0.7368    0.5385        38\n",
            "           4     0.6800    0.5620    0.6154       121\n",
            "           5     0.5686    0.5577    0.5631        52\n",
            "\n",
            "    accuracy                         0.6165       472\n",
            "   macro avg     0.6066    0.6292    0.6088       472\n",
            "weighted avg     0.6344    0.6165    0.6191       472\n",
            "\n",
            "[Епоха 5] Train Loss: 0.6852 | Train Acc: 73.52%\n",
            "[Епоха 5] Val Acc: 62.71%  |  Val F1 (weighted): 0.6242\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6542    0.6931    0.6731       101\n",
            "           1     0.5401    0.7551    0.6298        98\n",
            "           2     0.6269    0.6774    0.6512        62\n",
            "           3     0.5625    0.4737    0.5143        38\n",
            "           4     0.7838    0.4793    0.5949       121\n",
            "           5     0.6182    0.6538    0.6355        52\n",
            "\n",
            "    accuracy                         0.6271       472\n",
            "   macro avg     0.6309    0.6221    0.6164       472\n",
            "weighted avg     0.6488    0.6271    0.6242       472\n",
            "\n",
            "[Епоха 6] Train Loss: 0.5573 | Train Acc: 79.08%\n",
            "[Епоха 6] Val Acc: 62.92%  |  Val F1 (weighted): 0.6284\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6923    0.7129    0.7024       101\n",
            "           1     0.5319    0.7653    0.6276        98\n",
            "           2     0.7037    0.6129    0.6552        62\n",
            "           3     0.4412    0.7895    0.5660        38\n",
            "           4     0.8333    0.4545    0.5882       121\n",
            "           5     0.6923    0.5192    0.5934        52\n",
            "\n",
            "    accuracy                         0.6292       472\n",
            "   macro avg     0.6491    0.6424    0.6222       472\n",
            "weighted avg     0.6764    0.6292    0.6284       472\n",
            "\n",
            "[Епоха 7] Train Loss: 0.4834 | Train Acc: 81.89%\n",
            "[Епоха 7] Val Acc: 65.04%  |  Val F1 (weighted): 0.6469\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6762    0.7030    0.6893       101\n",
            "           1     0.5588    0.7755    0.6496        98\n",
            "           2     0.6875    0.7097    0.6984        62\n",
            "           3     0.5000    0.7632    0.6042        38\n",
            "           4     0.8281    0.4380    0.5730       121\n",
            "           5     0.7556    0.6538    0.7010        52\n",
            "\n",
            "    accuracy                         0.6504       472\n",
            "   macro avg     0.6677    0.6739    0.6526       472\n",
            "weighted avg     0.6868    0.6504    0.6469       472\n",
            "\n",
            "[Епоха 8] Train Loss: 0.4055 | Train Acc: 83.10%\n",
            "[Епоха 8] Val Acc: 65.68%  |  Val F1 (weighted): 0.6541\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7071    0.6931    0.7000       101\n",
            "           1     0.5615    0.7449    0.6404        98\n",
            "           2     0.6076    0.7742    0.6809        62\n",
            "           3     0.5435    0.6579    0.5952        38\n",
            "           4     0.8485    0.4628    0.5989       121\n",
            "           5     0.7308    0.7308    0.7308        52\n",
            "\n",
            "    accuracy                         0.6568       472\n",
            "   macro avg     0.6665    0.6773    0.6577       472\n",
            "weighted avg     0.6895    0.6568    0.6541       472\n",
            "\n",
            "[Епоха 9] Train Loss: 0.3660 | Train Acc: 85.28%\n",
            "[Епоха 9] Val Acc: 67.58%  |  Val F1 (weighted): 0.6760\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7586    0.6535    0.7021       101\n",
            "           1     0.5932    0.7143    0.6481        98\n",
            "           2     0.6049    0.7903    0.6853        62\n",
            "           3     0.5957    0.7368    0.6588        38\n",
            "           4     0.7816    0.5620    0.6538       121\n",
            "           5     0.7308    0.7308    0.7308        52\n",
            "\n",
            "    accuracy                         0.6758       472\n",
            "   macro avg     0.6775    0.6979    0.6798       472\n",
            "weighted avg     0.6938    0.6758    0.6760       472\n",
            "\n",
            "[Епоха 10] Train Loss: 0.2708 | Train Acc: 89.25%\n",
            "[Епоха 10] Val Acc: 69.28%  |  Val F1 (weighted): 0.6948\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6961    0.7030    0.6995       101\n",
            "           1     0.6602    0.6939    0.6766        98\n",
            "           2     0.6667    0.7097    0.6875        62\n",
            "           3     0.5400    0.7105    0.6136        38\n",
            "           4     0.8229    0.6529    0.7281       121\n",
            "           5     0.6909    0.7308    0.7103        52\n",
            "\n",
            "    accuracy                         0.6928       472\n",
            "   macro avg     0.6795    0.7001    0.6859       472\n",
            "weighted avg     0.7041    0.6928    0.6948       472\n",
            "\n",
            "[Епоха 11] Train Loss: 0.2585 | Train Acc: 90.36%\n",
            "[Епоха 11] Val Acc: 69.92%  |  Val F1 (weighted): 0.7005\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6972    0.7525    0.7238       101\n",
            "           1     0.6875    0.6735    0.6804        98\n",
            "           2     0.6765    0.7419    0.7077        62\n",
            "           3     0.5306    0.6842    0.5977        38\n",
            "           4     0.7545    0.6860    0.7186       121\n",
            "           5     0.8250    0.6346    0.7174        52\n",
            "\n",
            "    accuracy                         0.6992       472\n",
            "   macro avg     0.6952    0.6954    0.6909       472\n",
            "weighted avg     0.7078    0.6992    0.7005       472\n",
            "\n",
            "[Епоха 12] Train Loss: 0.2254 | Train Acc: 91.74%\n",
            "[Епоха 12] Val Acc: 70.55%  |  Val F1 (weighted): 0.7080\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7766    0.7228    0.7487       101\n",
            "           1     0.6667    0.6735    0.6701        98\n",
            "           2     0.6438    0.7581    0.6963        62\n",
            "           3     0.5200    0.6842    0.5909        38\n",
            "           4     0.7798    0.7025    0.7391       121\n",
            "           5     0.7660    0.6923    0.7273        52\n",
            "\n",
            "    accuracy                         0.7055       472\n",
            "   macro avg     0.6921    0.7056    0.6954       472\n",
            "weighted avg     0.7153    0.7055    0.7080       472\n",
            "\n",
            "[Епоха 13] Train Loss: 0.1643 | Train Acc: 94.07%\n",
            "[Епоха 13] Val Acc: 70.97%  |  Val F1 (weighted): 0.7096\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7264    0.7624    0.7440       101\n",
            "           1     0.6604    0.7143    0.6863        98\n",
            "           2     0.6622    0.7903    0.7206        62\n",
            "           3     0.6389    0.6053    0.6216        38\n",
            "           4     0.7670    0.6529    0.7054       121\n",
            "           5     0.7872    0.7115    0.7475        52\n",
            "\n",
            "    accuracy                         0.7097       472\n",
            "   macro avg     0.7070    0.7061    0.7042       472\n",
            "weighted avg     0.7143    0.7097    0.7096       472\n",
            "\n",
            "[Епоха 14] Train Loss: 0.1707 | Train Acc: 93.54%\n",
            "[Епоха 14] Val Acc: 69.49%  |  Val F1 (weighted): 0.6951\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7000    0.7624    0.7299       101\n",
            "           1     0.6989    0.6633    0.6806        98\n",
            "           2     0.7049    0.6935    0.6992        62\n",
            "           3     0.5641    0.5789    0.5714        38\n",
            "           4     0.7664    0.6777    0.7193       121\n",
            "           5     0.6290    0.7500    0.6842        52\n",
            "\n",
            "    accuracy                         0.6949       472\n",
            "   macro avg     0.6772    0.6876    0.6808       472\n",
            "weighted avg     0.6987    0.6949    0.6951       472\n",
            "\n",
            "[Епоха 15] Train Loss: 0.1568 | Train Acc: 94.23%\n",
            "[Епоха 15] Val Acc: 73.52%  |  Val F1 (weighted): 0.7356\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7549    0.7624    0.7586       101\n",
            "           1     0.7727    0.6939    0.7312        98\n",
            "           2     0.6438    0.7581    0.6963        62\n",
            "           3     0.6818    0.7895    0.7317        38\n",
            "           4     0.7739    0.7355    0.7542       121\n",
            "           5     0.7200    0.6923    0.7059        52\n",
            "\n",
            "    accuracy                         0.7352       472\n",
            "   macro avg     0.7245    0.7386    0.7297       472\n",
            "weighted avg     0.7392    0.7352    0.7356       472\n",
            "\n",
            "Найкращий Val F1 (weighted): 0.7356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b03e462-6a1d-4d51-a55b-9e7ff8aea769",
      "metadata": {
        "id": "1b03e462-6a1d-4d51-a55b-9e7ff8aea769"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}